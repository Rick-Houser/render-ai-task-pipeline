services:
  - type: web
    name: api
    runtime: python
    rootDir: backend
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: ai_task_db
          property: connectionString
      - key: REDIS_URL
        fromService:
          type: redis
          name: task_queue
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false
    autoDeploy: true

  - type: web
    name: frontend
    runtime: static
    rootDir: frontend
    buildCommand: npm install && npm run build
    staticPublishPath: dist
    autoDeploy: true

  - type: worker
    name: task_worker
    runtime: python
    rootDir: backend
    buildCommand: pip install -r requirements.txt
    startCommand: celery -A celery_app worker --loglevel=info
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: ai_task_db
          property: connectionString
      - key: REDIS_URL
        fromService:
          type: redis
          name: task_queue
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false
    scaling:
      minInstances: 1
      maxInstances: 5
      targetCPUPercent: 70

  - type: cron
    name: daily_summary
    runtime: python
    rootDir: cron
    buildCommand: pip install -r ../backend/requirements.txt
    startCommand: python daily_summary.py
    schedule: "0 0 * * *"
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: ai_task_db
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false

  - type: keyvalue
    name: task_queue
    plan: standard
    ipAllowList:
      - source: 0.0.0.0/0
        description: Allow all external connections

databases:
  - name: ai_task_db
    databaseName: ai_task_db
    user: ai_user
    plan: standard
    postgresMajorVersion: "15"