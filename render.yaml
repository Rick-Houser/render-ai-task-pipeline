services:
  - type: web
    name: api
    env: python
    repo: https://github.com/your-repo/render-ai-task-pipeline
    buildCommand: pip install -r backend/requirements.txt
    startCommand: cd backend && uvicorn main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: ai_task_db
          property: connectionString
      - key: REDIS_URL
        fromService:
          type: redis
          name: task_queue
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false
    autoDeploy: true

  - type: web
    name: frontend
    env: static
    repo: https://github.com/your-repo/render-ai-task-pipeline
    rootDir: frontend
    buildCommand: npm install && npm run build
    publishPath: dist
    autoDeploy: true

  - type: worker
    name: task_worker
    env: python
    repo: https://github.com/your-repo/render-ai-task-pipeline
    buildCommand: pip install -r backend/requirements.txt
    startCommand: cd backend && celery -A celery_app worker --loglevel=info
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: ai_task_db
          property: connectionString
      - key: REDIS_URL
        fromService:
          type: redis
          name: task_queue
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false
    autoScale:
      enabled: true
      min: 1
      max: 5
      cpu: 70

  - type: cron
    name: daily_summary
    env: python
    repo: https://github.com/your-repo/render-ai-task-pipeline
    buildCommand: pip install -r backend/requirements.txt
    startCommand: cd cron && python daily_summary.py
    schedule: "0 0 * * *"
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: ai_task_db
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false

databases:
  - name: ai_task_db
    databaseName: ai_task_db
    user: ai_user
    plan: standard
    postgresMajorVersion: 15

redis:
  - name: task_queue
    plan: standard